// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/speech/v1/cloud-speech.proto

package com.google.cloud.speech.v1;

/**
 * <pre>
 * The `InitialRecognizeRequest` message provides information to the recognizer
 * that specifies how to process the request.
 * </pre>
 *
 * Protobuf type {@code google.cloud.speech.v1.InitialRecognizeRequest}
 */
public  final class InitialRecognizeRequest extends
    com.google.protobuf.GeneratedMessage implements
    // @@protoc_insertion_point(message_implements:google.cloud.speech.v1.InitialRecognizeRequest)
    InitialRecognizeRequestOrBuilder {
  // Use InitialRecognizeRequest.newBuilder() to construct.
  private InitialRecognizeRequest(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
    super(builder);
  }
  private InitialRecognizeRequest() {
    encoding_ = 0;
    sampleRate_ = 0;
    languageCode_ = "";
    maxAlternatives_ = 0;
    profanityFilter_ = false;
    continuous_ = false;
    interimResults_ = false;
    enableEndpointerEvents_ = false;
    outputUri_ = "";
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
  }
  private InitialRecognizeRequest(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    int mutable_bitField0_ = 0;
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          default: {
            if (!input.skipField(tag)) {
              done = true;
            }
            break;
          }
          case 8: {
            int rawValue = input.readEnum();

            encoding_ = rawValue;
            break;
          }
          case 16: {

            sampleRate_ = input.readInt32();
            break;
          }
          case 26: {
            java.lang.String s = input.readStringRequireUtf8();

            languageCode_ = s;
            break;
          }
          case 32: {

            maxAlternatives_ = input.readInt32();
            break;
          }
          case 40: {

            profanityFilter_ = input.readBool();
            break;
          }
          case 48: {

            continuous_ = input.readBool();
            break;
          }
          case 56: {

            interimResults_ = input.readBool();
            break;
          }
          case 64: {

            enableEndpointerEvents_ = input.readBool();
            break;
          }
          case 74: {
            java.lang.String s = input.readStringRequireUtf8();

            outputUri_ = s;
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return com.google.cloud.speech.v1.SpeechProto.internal_static_google_cloud_speech_v1_InitialRecognizeRequest_descriptor;
  }

  protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.speech.v1.SpeechProto.internal_static_google_cloud_speech_v1_InitialRecognizeRequest_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.speech.v1.InitialRecognizeRequest.class, com.google.cloud.speech.v1.InitialRecognizeRequest.Builder.class);
  }

  /**
   * <pre>
   * Audio encoding of the data sent in the audio message.
   * </pre>
   *
   * Protobuf enum {@code google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding}
   */
  public enum AudioEncoding
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     * Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * </pre>
     *
     * <code>ENCODING_UNSPECIFIED = 0;</code>
     */
    ENCODING_UNSPECIFIED(0),
    /**
     * <pre>
     * Uncompressed 16-bit signed little-endian samples.
     * This is the simplest encoding format, useful for getting started.
     * However, because it is uncompressed, it is not recommended for deployed
     * clients.
     * </pre>
     *
     * <code>LINEAR16 = 1;</code>
     */
    LINEAR16(1),
    /**
     * <pre>
     * This is the recommended encoding format because it uses lossless
     * compression; therefore recognition accuracy is not compromised by a lossy
     * codec.
     * The stream FLAC format is specified at:
     * http://flac.sourceforge.net/documentation.html.
     * Only 16-bit samples are supported.
     * Not all fields in STREAMINFO are supported.
     * </pre>
     *
     * <code>FLAC = 2;</code>
     */
    FLAC(2),
    /**
     * <pre>
     * 8-bit samples that compand 14-bit audio samples using PCMU/mu-law.
     * </pre>
     *
     * <code>MULAW = 3;</code>
     */
    MULAW(3),
    /**
     * <pre>
     * Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
     * </pre>
     *
     * <code>AMR = 4;</code>
     */
    AMR(4),
    /**
     * <pre>
     * Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
     * </pre>
     *
     * <code>AMR_WB = 5;</code>
     */
    AMR_WB(5),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     * Not specified. Will return result [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * </pre>
     *
     * <code>ENCODING_UNSPECIFIED = 0;</code>
     */
    public static final int ENCODING_UNSPECIFIED_VALUE = 0;
    /**
     * <pre>
     * Uncompressed 16-bit signed little-endian samples.
     * This is the simplest encoding format, useful for getting started.
     * However, because it is uncompressed, it is not recommended for deployed
     * clients.
     * </pre>
     *
     * <code>LINEAR16 = 1;</code>
     */
    public static final int LINEAR16_VALUE = 1;
    /**
     * <pre>
     * This is the recommended encoding format because it uses lossless
     * compression; therefore recognition accuracy is not compromised by a lossy
     * codec.
     * The stream FLAC format is specified at:
     * http://flac.sourceforge.net/documentation.html.
     * Only 16-bit samples are supported.
     * Not all fields in STREAMINFO are supported.
     * </pre>
     *
     * <code>FLAC = 2;</code>
     */
    public static final int FLAC_VALUE = 2;
    /**
     * <pre>
     * 8-bit samples that compand 14-bit audio samples using PCMU/mu-law.
     * </pre>
     *
     * <code>MULAW = 3;</code>
     */
    public static final int MULAW_VALUE = 3;
    /**
     * <pre>
     * Adaptive Multi-Rate Narrowband codec. `sample_rate` must be 8000 Hz.
     * </pre>
     *
     * <code>AMR = 4;</code>
     */
    public static final int AMR_VALUE = 4;
    /**
     * <pre>
     * Adaptive Multi-Rate Wideband codec. `sample_rate` must be 16000 Hz.
     * </pre>
     *
     * <code>AMR_WB = 5;</code>
     */
    public static final int AMR_WB_VALUE = 5;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new java.lang.IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AudioEncoding valueOf(int value) {
      return forNumber(value);
    }

    public static AudioEncoding forNumber(int value) {
      switch (value) {
        case 0: return ENCODING_UNSPECIFIED;
        case 1: return LINEAR16;
        case 2: return FLAC;
        case 3: return MULAW;
        case 4: return AMR;
        case 5: return AMR_WB;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AudioEncoding>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        AudioEncoding> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AudioEncoding>() {
            public AudioEncoding findValueByNumber(int number) {
              return AudioEncoding.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return com.google.cloud.speech.v1.InitialRecognizeRequest.getDescriptor().getEnumTypes().get(0);
    }

    private static final AudioEncoding[] VALUES = values();

    public static AudioEncoding valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private AudioEncoding(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding)
  }

  public static final int ENCODING_FIELD_NUMBER = 1;
  private int encoding_;
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `AudioRequest` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
   */
  public int getEncodingValue() {
    return encoding_;
  }
  /**
   * <pre>
   * [Required] Encoding of audio data sent in all `AudioRequest` messages.
   * </pre>
   *
   * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
   */
  public com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding getEncoding() {
    com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding result = com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.forNumber(encoding_);
    return result == null ? com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.UNRECOGNIZED : result;
  }

  public static final int SAMPLE_RATE_FIELD_NUMBER = 2;
  private int sampleRate_;
  /**
   * <pre>
   * [Required] Sample rate in Hertz of the audio data sent in all
   * AudioRequest messages.
   * 16000 is optimal. Valid values are: 8000-48000.
   * </pre>
   *
   * <code>optional int32 sample_rate = 2;</code>
   */
  public int getSampleRate() {
    return sampleRate_;
  }

  public static final int LANGUAGE_CODE_FIELD_NUMBER = 3;
  private volatile java.lang.Object languageCode_;
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US".
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  public java.lang.String getLanguageCode() {
    java.lang.Object ref = languageCode_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      languageCode_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * [Optional] The language of the supplied audio as a BCP-47 language tag.
   * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
   * If omitted, defaults to "en-US".
   * </pre>
   *
   * <code>optional string language_code = 3;</code>
   */
  public com.google.protobuf.ByteString
      getLanguageCodeBytes() {
    java.lang.Object ref = languageCode_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      languageCode_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  public static final int MAX_ALTERNATIVES_FIELD_NUMBER = 4;
  private int maxAlternatives_;
  /**
   * <pre>
   * [Optional] Maximum number of recognition hypotheses to be returned.
   * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
   * within each `SpeechRecognitionResult`.
   * The server may return fewer than `max_alternatives`.
   * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
   * `1`. If omitted, defaults to `1`.
   * </pre>
   *
   * <code>optional int32 max_alternatives = 4;</code>
   */
  public int getMaxAlternatives() {
    return maxAlternatives_;
  }

  public static final int PROFANITY_FILTER_FIELD_NUMBER = 5;
  private boolean profanityFilter_;
  /**
   * <pre>
   * [Optional] If set to `true`, the server will attempt to filter out
   * profanities, replacing all but the initial character in each filtered word
   * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
   * won't be filtered out.
   * </pre>
   *
   * <code>optional bool profanity_filter = 5;</code>
   */
  public boolean getProfanityFilter() {
    return profanityFilter_;
  }

  public static final int CONTINUOUS_FIELD_NUMBER = 6;
  private boolean continuous_;
  /**
   * <pre>
   * [Optional] If `false` or omitted, the recognizer will detect a single
   * spoken utterance, and it will cease recognition when the user stops
   * speaking. If `enable_endpointer_events` is `true`, it will return
   * `END_OF_UTTERANCE` when it detects that the user has stopped speaking.
   * In all cases, it will return no more than one `SpeechRecognitionResult`,
   * and set the `is_final` flag to `true`.
   * If `true`, the recognizer will continue recognition (even if the user
   * pauses speaking) until the client sends an `end_of_data` message or when
   * the maximum time limit has been reached. Multiple
   * `SpeechRecognitionResult`s with the `is_final` flag set to `true` may be
   * returned to indicate that the recognizer will not return any further
   * hypotheses for this portion of the transcript.
   * </pre>
   *
   * <code>optional bool continuous = 6;</code>
   */
  public boolean getContinuous() {
    return continuous_;
  }

  public static final int INTERIM_RESULTS_FIELD_NUMBER = 7;
  private boolean interimResults_;
  /**
   * <pre>
   * [Optional] If this parameter is `true`, interim results may be returned as
   * they become available.
   * If `false` or omitted, only `is_final=true` result(s) are returned.
   * </pre>
   *
   * <code>optional bool interim_results = 7;</code>
   */
  public boolean getInterimResults() {
    return interimResults_;
  }

  public static final int ENABLE_ENDPOINTER_EVENTS_FIELD_NUMBER = 8;
  private boolean enableEndpointerEvents_;
  /**
   * <pre>
   * [Optional] If this parameter is `true`, `EndpointerEvents` may be returned
   * as they become available.
   * If `false` or omitted, no `EndpointerEvents` are returned.
   * </pre>
   *
   * <code>optional bool enable_endpointer_events = 8;</code>
   */
  public boolean getEnableEndpointerEvents() {
    return enableEndpointerEvents_;
  }

  public static final int OUTPUT_URI_FIELD_NUMBER = 9;
  private volatile java.lang.Object outputUri_;
  /**
   * <pre>
   * [Optional] URI that points to a file where the recognition result should
   * be stored in JSON format. If omitted or empty string, the recognition
   * result is returned in the response. Should be specified only for
   * `NonStreamingRecognize`. If specified in a `Recognize` request,
   * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
   * If specified in a `NonStreamingRecognize` request,
   * `NonStreamingRecognize` returns immediately, and the output file
   * is created asynchronously once the audio processing completes.
   * Currently, only Google Cloud Storage URIs are supported, which must be
   * specified in the following format: `gs://bucket_name/object_name`
   * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
   * more information, see [Request URIs](/storage/docs/reference-uris).
   * </pre>
   *
   * <code>optional string output_uri = 9;</code>
   */
  public java.lang.String getOutputUri() {
    java.lang.Object ref = outputUri_;
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      outputUri_ = s;
      return s;
    }
  }
  /**
   * <pre>
   * [Optional] URI that points to a file where the recognition result should
   * be stored in JSON format. If omitted or empty string, the recognition
   * result is returned in the response. Should be specified only for
   * `NonStreamingRecognize`. If specified in a `Recognize` request,
   * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
   * If specified in a `NonStreamingRecognize` request,
   * `NonStreamingRecognize` returns immediately, and the output file
   * is created asynchronously once the audio processing completes.
   * Currently, only Google Cloud Storage URIs are supported, which must be
   * specified in the following format: `gs://bucket_name/object_name`
   * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
   * more information, see [Request URIs](/storage/docs/reference-uris).
   * </pre>
   *
   * <code>optional string output_uri = 9;</code>
   */
  public com.google.protobuf.ByteString
      getOutputUriBytes() {
    java.lang.Object ref = outputUri_;
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      outputUri_ = b;
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  private byte memoizedIsInitialized = -1;
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (encoding_ != com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
      output.writeEnum(1, encoding_);
    }
    if (sampleRate_ != 0) {
      output.writeInt32(2, sampleRate_);
    }
    if (!getLanguageCodeBytes().isEmpty()) {
      com.google.protobuf.GeneratedMessage.writeString(output, 3, languageCode_);
    }
    if (maxAlternatives_ != 0) {
      output.writeInt32(4, maxAlternatives_);
    }
    if (profanityFilter_ != false) {
      output.writeBool(5, profanityFilter_);
    }
    if (continuous_ != false) {
      output.writeBool(6, continuous_);
    }
    if (interimResults_ != false) {
      output.writeBool(7, interimResults_);
    }
    if (enableEndpointerEvents_ != false) {
      output.writeBool(8, enableEndpointerEvents_);
    }
    if (!getOutputUriBytes().isEmpty()) {
      com.google.protobuf.GeneratedMessage.writeString(output, 9, outputUri_);
    }
  }

  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (encoding_ != com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
      size += com.google.protobuf.CodedOutputStream
        .computeEnumSize(1, encoding_);
    }
    if (sampleRate_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(2, sampleRate_);
    }
    if (!getLanguageCodeBytes().isEmpty()) {
      size += com.google.protobuf.GeneratedMessage.computeStringSize(3, languageCode_);
    }
    if (maxAlternatives_ != 0) {
      size += com.google.protobuf.CodedOutputStream
        .computeInt32Size(4, maxAlternatives_);
    }
    if (profanityFilter_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(5, profanityFilter_);
    }
    if (continuous_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(6, continuous_);
    }
    if (interimResults_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(7, interimResults_);
    }
    if (enableEndpointerEvents_ != false) {
      size += com.google.protobuf.CodedOutputStream
        .computeBoolSize(8, enableEndpointerEvents_);
    }
    if (!getOutputUriBytes().isEmpty()) {
      size += com.google.protobuf.GeneratedMessage.computeStringSize(9, outputUri_);
    }
    memoizedSize = size;
    return size;
  }

  private static final long serialVersionUID = 0L;
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1.InitialRecognizeRequest parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.cloud.speech.v1.InitialRecognizeRequest prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessage.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * The `InitialRecognizeRequest` message provides information to the recognizer
   * that specifies how to process the request.
   * </pre>
   *
   * Protobuf type {@code google.cloud.speech.v1.InitialRecognizeRequest}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessage.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:google.cloud.speech.v1.InitialRecognizeRequest)
      com.google.cloud.speech.v1.InitialRecognizeRequestOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.speech.v1.SpeechProto.internal_static_google_cloud_speech_v1_InitialRecognizeRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.speech.v1.SpeechProto.internal_static_google_cloud_speech_v1_InitialRecognizeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.speech.v1.InitialRecognizeRequest.class, com.google.cloud.speech.v1.InitialRecognizeRequest.Builder.class);
    }

    // Construct using com.google.cloud.speech.v1.InitialRecognizeRequest.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
      }
    }
    public Builder clear() {
      super.clear();
      encoding_ = 0;

      sampleRate_ = 0;

      languageCode_ = "";

      maxAlternatives_ = 0;

      profanityFilter_ = false;

      continuous_ = false;

      interimResults_ = false;

      enableEndpointerEvents_ = false;

      outputUri_ = "";

      return this;
    }

    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return com.google.cloud.speech.v1.SpeechProto.internal_static_google_cloud_speech_v1_InitialRecognizeRequest_descriptor;
    }

    public com.google.cloud.speech.v1.InitialRecognizeRequest getDefaultInstanceForType() {
      return com.google.cloud.speech.v1.InitialRecognizeRequest.getDefaultInstance();
    }

    public com.google.cloud.speech.v1.InitialRecognizeRequest build() {
      com.google.cloud.speech.v1.InitialRecognizeRequest result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    public com.google.cloud.speech.v1.InitialRecognizeRequest buildPartial() {
      com.google.cloud.speech.v1.InitialRecognizeRequest result = new com.google.cloud.speech.v1.InitialRecognizeRequest(this);
      result.encoding_ = encoding_;
      result.sampleRate_ = sampleRate_;
      result.languageCode_ = languageCode_;
      result.maxAlternatives_ = maxAlternatives_;
      result.profanityFilter_ = profanityFilter_;
      result.continuous_ = continuous_;
      result.interimResults_ = interimResults_;
      result.enableEndpointerEvents_ = enableEndpointerEvents_;
      result.outputUri_ = outputUri_;
      onBuilt();
      return result;
    }

    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.speech.v1.InitialRecognizeRequest) {
        return mergeFrom((com.google.cloud.speech.v1.InitialRecognizeRequest)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.speech.v1.InitialRecognizeRequest other) {
      if (other == com.google.cloud.speech.v1.InitialRecognizeRequest.getDefaultInstance()) return this;
      if (other.encoding_ != 0) {
        setEncodingValue(other.getEncodingValue());
      }
      if (other.getSampleRate() != 0) {
        setSampleRate(other.getSampleRate());
      }
      if (!other.getLanguageCode().isEmpty()) {
        languageCode_ = other.languageCode_;
        onChanged();
      }
      if (other.getMaxAlternatives() != 0) {
        setMaxAlternatives(other.getMaxAlternatives());
      }
      if (other.getProfanityFilter() != false) {
        setProfanityFilter(other.getProfanityFilter());
      }
      if (other.getContinuous() != false) {
        setContinuous(other.getContinuous());
      }
      if (other.getInterimResults() != false) {
        setInterimResults(other.getInterimResults());
      }
      if (other.getEnableEndpointerEvents() != false) {
        setEnableEndpointerEvents(other.getEnableEndpointerEvents());
      }
      if (!other.getOutputUri().isEmpty()) {
        outputUri_ = other.outputUri_;
        onChanged();
      }
      onChanged();
      return this;
    }

    public final boolean isInitialized() {
      return true;
    }

    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      com.google.cloud.speech.v1.InitialRecognizeRequest parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (com.google.cloud.speech.v1.InitialRecognizeRequest) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }

    private int encoding_ = 0;
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `AudioRequest` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
     */
    public int getEncodingValue() {
      return encoding_;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `AudioRequest` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
     */
    public Builder setEncodingValue(int value) {
      encoding_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `AudioRequest` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
     */
    public com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding getEncoding() {
      com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding result = com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.forNumber(encoding_);
      return result == null ? com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding.UNRECOGNIZED : result;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `AudioRequest` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
     */
    public Builder setEncoding(com.google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding value) {
      if (value == null) {
        throw new NullPointerException();
      }
      
      encoding_ = value.getNumber();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Required] Encoding of audio data sent in all `AudioRequest` messages.
     * </pre>
     *
     * <code>optional .google.cloud.speech.v1.InitialRecognizeRequest.AudioEncoding encoding = 1;</code>
     */
    public Builder clearEncoding() {
      
      encoding_ = 0;
      onChanged();
      return this;
    }

    private int sampleRate_ ;
    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * AudioRequest messages.
     * 16000 is optimal. Valid values are: 8000-48000.
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public int getSampleRate() {
      return sampleRate_;
    }
    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * AudioRequest messages.
     * 16000 is optimal. Valid values are: 8000-48000.
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public Builder setSampleRate(int value) {
      
      sampleRate_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Required] Sample rate in Hertz of the audio data sent in all
     * AudioRequest messages.
     * 16000 is optimal. Valid values are: 8000-48000.
     * </pre>
     *
     * <code>optional int32 sample_rate = 2;</code>
     */
    public Builder clearSampleRate() {
      
      sampleRate_ = 0;
      onChanged();
      return this;
    }

    private java.lang.Object languageCode_ = "";
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US".
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public java.lang.String getLanguageCode() {
      java.lang.Object ref = languageCode_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        languageCode_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US".
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public com.google.protobuf.ByteString
        getLanguageCodeBytes() {
      java.lang.Object ref = languageCode_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        languageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US".
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder setLanguageCode(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      languageCode_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US".
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder clearLanguageCode() {
      
      languageCode_ = getDefaultInstance().getLanguageCode();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] The language of the supplied audio as a BCP-47 language tag.
     * Example: "en-GB"  https://www.rfc-editor.org/rfc/bcp/bcp47.txt
     * If omitted, defaults to "en-US".
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public Builder setLanguageCodeBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      languageCode_ = value;
      onChanged();
      return this;
    }

    private int maxAlternatives_ ;
    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public int getMaxAlternatives() {
      return maxAlternatives_;
    }
    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public Builder setMaxAlternatives(int value) {
      
      maxAlternatives_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognitionAlternative` messages
     * within each `SpeechRecognitionResult`.
     * The server may return fewer than `max_alternatives`.
     * Valid values are `0`-`30`. A value of `0` or `1` will return a maximum of
     * `1`. If omitted, defaults to `1`.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public Builder clearMaxAlternatives() {
      
      maxAlternatives_ = 0;
      onChanged();
      return this;
    }

    private boolean profanityFilter_ ;
    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public boolean getProfanityFilter() {
      return profanityFilter_;
    }
    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public Builder setProfanityFilter(boolean value) {
      
      profanityFilter_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] If set to `true`, the server will attempt to filter out
     * profanities, replacing all but the initial character in each filtered word
     * with asterisks, e.g. "f***". If set to `false` or omitted, profanities
     * won't be filtered out.
     * </pre>
     *
     * <code>optional bool profanity_filter = 5;</code>
     */
    public Builder clearProfanityFilter() {
      
      profanityFilter_ = false;
      onChanged();
      return this;
    }

    private boolean continuous_ ;
    /**
     * <pre>
     * [Optional] If `false` or omitted, the recognizer will detect a single
     * spoken utterance, and it will cease recognition when the user stops
     * speaking. If `enable_endpointer_events` is `true`, it will return
     * `END_OF_UTTERANCE` when it detects that the user has stopped speaking.
     * In all cases, it will return no more than one `SpeechRecognitionResult`,
     * and set the `is_final` flag to `true`.
     * If `true`, the recognizer will continue recognition (even if the user
     * pauses speaking) until the client sends an `end_of_data` message or when
     * the maximum time limit has been reached. Multiple
     * `SpeechRecognitionResult`s with the `is_final` flag set to `true` may be
     * returned to indicate that the recognizer will not return any further
     * hypotheses for this portion of the transcript.
     * </pre>
     *
     * <code>optional bool continuous = 6;</code>
     */
    public boolean getContinuous() {
      return continuous_;
    }
    /**
     * <pre>
     * [Optional] If `false` or omitted, the recognizer will detect a single
     * spoken utterance, and it will cease recognition when the user stops
     * speaking. If `enable_endpointer_events` is `true`, it will return
     * `END_OF_UTTERANCE` when it detects that the user has stopped speaking.
     * In all cases, it will return no more than one `SpeechRecognitionResult`,
     * and set the `is_final` flag to `true`.
     * If `true`, the recognizer will continue recognition (even if the user
     * pauses speaking) until the client sends an `end_of_data` message or when
     * the maximum time limit has been reached. Multiple
     * `SpeechRecognitionResult`s with the `is_final` flag set to `true` may be
     * returned to indicate that the recognizer will not return any further
     * hypotheses for this portion of the transcript.
     * </pre>
     *
     * <code>optional bool continuous = 6;</code>
     */
    public Builder setContinuous(boolean value) {
      
      continuous_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] If `false` or omitted, the recognizer will detect a single
     * spoken utterance, and it will cease recognition when the user stops
     * speaking. If `enable_endpointer_events` is `true`, it will return
     * `END_OF_UTTERANCE` when it detects that the user has stopped speaking.
     * In all cases, it will return no more than one `SpeechRecognitionResult`,
     * and set the `is_final` flag to `true`.
     * If `true`, the recognizer will continue recognition (even if the user
     * pauses speaking) until the client sends an `end_of_data` message or when
     * the maximum time limit has been reached. Multiple
     * `SpeechRecognitionResult`s with the `is_final` flag set to `true` may be
     * returned to indicate that the recognizer will not return any further
     * hypotheses for this portion of the transcript.
     * </pre>
     *
     * <code>optional bool continuous = 6;</code>
     */
    public Builder clearContinuous() {
      
      continuous_ = false;
      onChanged();
      return this;
    }

    private boolean interimResults_ ;
    /**
     * <pre>
     * [Optional] If this parameter is `true`, interim results may be returned as
     * they become available.
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>optional bool interim_results = 7;</code>
     */
    public boolean getInterimResults() {
      return interimResults_;
    }
    /**
     * <pre>
     * [Optional] If this parameter is `true`, interim results may be returned as
     * they become available.
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>optional bool interim_results = 7;</code>
     */
    public Builder setInterimResults(boolean value) {
      
      interimResults_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] If this parameter is `true`, interim results may be returned as
     * they become available.
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>optional bool interim_results = 7;</code>
     */
    public Builder clearInterimResults() {
      
      interimResults_ = false;
      onChanged();
      return this;
    }

    private boolean enableEndpointerEvents_ ;
    /**
     * <pre>
     * [Optional] If this parameter is `true`, `EndpointerEvents` may be returned
     * as they become available.
     * If `false` or omitted, no `EndpointerEvents` are returned.
     * </pre>
     *
     * <code>optional bool enable_endpointer_events = 8;</code>
     */
    public boolean getEnableEndpointerEvents() {
      return enableEndpointerEvents_;
    }
    /**
     * <pre>
     * [Optional] If this parameter is `true`, `EndpointerEvents` may be returned
     * as they become available.
     * If `false` or omitted, no `EndpointerEvents` are returned.
     * </pre>
     *
     * <code>optional bool enable_endpointer_events = 8;</code>
     */
    public Builder setEnableEndpointerEvents(boolean value) {
      
      enableEndpointerEvents_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] If this parameter is `true`, `EndpointerEvents` may be returned
     * as they become available.
     * If `false` or omitted, no `EndpointerEvents` are returned.
     * </pre>
     *
     * <code>optional bool enable_endpointer_events = 8;</code>
     */
    public Builder clearEnableEndpointerEvents() {
      
      enableEndpointerEvents_ = false;
      onChanged();
      return this;
    }

    private java.lang.Object outputUri_ = "";
    /**
     * <pre>
     * [Optional] URI that points to a file where the recognition result should
     * be stored in JSON format. If omitted or empty string, the recognition
     * result is returned in the response. Should be specified only for
     * `NonStreamingRecognize`. If specified in a `Recognize` request,
     * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * If specified in a `NonStreamingRecognize` request,
     * `NonStreamingRecognize` returns immediately, and the output file
     * is created asynchronously once the audio processing completes.
     * Currently, only Google Cloud Storage URIs are supported, which must be
     * specified in the following format: `gs://bucket_name/object_name`
     * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
     * more information, see [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string output_uri = 9;</code>
     */
    public java.lang.String getOutputUri() {
      java.lang.Object ref = outputUri_;
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        outputUri_ = s;
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * [Optional] URI that points to a file where the recognition result should
     * be stored in JSON format. If omitted or empty string, the recognition
     * result is returned in the response. Should be specified only for
     * `NonStreamingRecognize`. If specified in a `Recognize` request,
     * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * If specified in a `NonStreamingRecognize` request,
     * `NonStreamingRecognize` returns immediately, and the output file
     * is created asynchronously once the audio processing completes.
     * Currently, only Google Cloud Storage URIs are supported, which must be
     * specified in the following format: `gs://bucket_name/object_name`
     * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
     * more information, see [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string output_uri = 9;</code>
     */
    public com.google.protobuf.ByteString
        getOutputUriBytes() {
      java.lang.Object ref = outputUri_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        outputUri_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * [Optional] URI that points to a file where the recognition result should
     * be stored in JSON format. If omitted or empty string, the recognition
     * result is returned in the response. Should be specified only for
     * `NonStreamingRecognize`. If specified in a `Recognize` request,
     * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * If specified in a `NonStreamingRecognize` request,
     * `NonStreamingRecognize` returns immediately, and the output file
     * is created asynchronously once the audio processing completes.
     * Currently, only Google Cloud Storage URIs are supported, which must be
     * specified in the following format: `gs://bucket_name/object_name`
     * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
     * more information, see [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string output_uri = 9;</code>
     */
    public Builder setOutputUri(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  
      outputUri_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] URI that points to a file where the recognition result should
     * be stored in JSON format. If omitted or empty string, the recognition
     * result is returned in the response. Should be specified only for
     * `NonStreamingRecognize`. If specified in a `Recognize` request,
     * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * If specified in a `NonStreamingRecognize` request,
     * `NonStreamingRecognize` returns immediately, and the output file
     * is created asynchronously once the audio processing completes.
     * Currently, only Google Cloud Storage URIs are supported, which must be
     * specified in the following format: `gs://bucket_name/object_name`
     * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
     * more information, see [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string output_uri = 9;</code>
     */
    public Builder clearOutputUri() {
      
      outputUri_ = getDefaultInstance().getOutputUri();
      onChanged();
      return this;
    }
    /**
     * <pre>
     * [Optional] URI that points to a file where the recognition result should
     * be stored in JSON format. If omitted or empty string, the recognition
     * result is returned in the response. Should be specified only for
     * `NonStreamingRecognize`. If specified in a `Recognize` request,
     * `Recognize` returns [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT].
     * If specified in a `NonStreamingRecognize` request,
     * `NonStreamingRecognize` returns immediately, and the output file
     * is created asynchronously once the audio processing completes.
     * Currently, only Google Cloud Storage URIs are supported, which must be
     * specified in the following format: `gs://bucket_name/object_name`
     * (other URI formats return [google.rpc.Code.INVALID_ARGUMENT][google.rpc.Code.INVALID_ARGUMENT]). For
     * more information, see [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string output_uri = 9;</code>
     */
    public Builder setOutputUriBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      
      outputUri_ = value;
      onChanged();
      return this;
    }
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }

    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }


    // @@protoc_insertion_point(builder_scope:google.cloud.speech.v1.InitialRecognizeRequest)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1.InitialRecognizeRequest)
  private static final com.google.cloud.speech.v1.InitialRecognizeRequest DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new com.google.cloud.speech.v1.InitialRecognizeRequest();
  }

  public static com.google.cloud.speech.v1.InitialRecognizeRequest getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<InitialRecognizeRequest>
      PARSER = new com.google.protobuf.AbstractParser<InitialRecognizeRequest>() {
    public InitialRecognizeRequest parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
        return new InitialRecognizeRequest(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<InitialRecognizeRequest> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<InitialRecognizeRequest> getParserForType() {
    return PARSER;
  }

  public com.google.cloud.speech.v1.InitialRecognizeRequest getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

