// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: google/speech/v1beta1/cloud_speech.proto

package com.google.cloud.speech.v1beta1;

/**
 * <pre>
 * Contains audio data in the encoding specified in the `RecognitionConfig`.
 * Either `content` or `uri` must be supplied. Supplying both or neither
 * returns [google.rpc.Code.INVALID_ARGUMENT][].
 * </pre>
 *
 * Protobuf type {@code google.cloud.speech.v1beta1.RecognitionAudio}
 */
public  final class RecognitionAudio extends
    com.google.protobuf.GeneratedMessage implements
    // @@protoc_insertion_point(message_implements:google.cloud.speech.v1beta1.RecognitionAudio)
    RecognitionAudioOrBuilder {
  // Use RecognitionAudio.newBuilder() to construct.
  private RecognitionAudio(com.google.protobuf.GeneratedMessage.Builder<?> builder) {
    super(builder);
  }
  private RecognitionAudio() {
  }

  @java.lang.Override
  public final com.google.protobuf.UnknownFieldSet
  getUnknownFields() {
    return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
  }
  private RecognitionAudio(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    this();
    int mutable_bitField0_ = 0;
    try {
      boolean done = false;
      while (!done) {
        int tag = input.readTag();
        switch (tag) {
          case 0:
            done = true;
            break;
          default: {
            if (!input.skipField(tag)) {
              done = true;
            }
            break;
          }
          case 10: {
            audioSourceCase_ = 1;
            audioSource_ = input.readBytes();
            break;
          }
          case 18: {
            java.lang.String s = input.readStringRequireUtf8();
            audioSourceCase_ = 2;
            audioSource_ = s;
            break;
          }
        }
      }
    } catch (com.google.protobuf.InvalidProtocolBufferException e) {
      throw e.setUnfinishedMessage(this);
    } catch (java.io.IOException e) {
      throw new com.google.protobuf.InvalidProtocolBufferException(
          e).setUnfinishedMessage(this);
    } finally {
      makeExtensionsImmutable();
    }
  }
  public static final com.google.protobuf.Descriptors.Descriptor
      getDescriptor() {
    return com.google.cloud.speech.v1beta1.SpeechProto.internal_static_google_cloud_speech_v1beta1_RecognitionAudio_descriptor;
  }

  protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
      internalGetFieldAccessorTable() {
    return com.google.cloud.speech.v1beta1.SpeechProto.internal_static_google_cloud_speech_v1beta1_RecognitionAudio_fieldAccessorTable
        .ensureFieldAccessorsInitialized(
            com.google.cloud.speech.v1beta1.RecognitionAudio.class, com.google.cloud.speech.v1beta1.RecognitionAudio.Builder.class);
  }

  private int audioSourceCase_ = 0;
  private java.lang.Object audioSource_;
  public enum AudioSourceCase
      implements com.google.protobuf.Internal.EnumLite {
    CONTENT(1),
    URI(2),
    AUDIOSOURCE_NOT_SET(0);
    private final int value;
    private AudioSourceCase(int value) {
      this.value = value;
    }
    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AudioSourceCase valueOf(int value) {
      return forNumber(value);
    }

    public static AudioSourceCase forNumber(int value) {
      switch (value) {
        case 1: return CONTENT;
        case 2: return URI;
        case 0: return AUDIOSOURCE_NOT_SET;
        default: return null;
      }
    }
    public int getNumber() {
      return this.value;
    }
  };

  public AudioSourceCase
  getAudioSourceCase() {
    return AudioSourceCase.forNumber(
        audioSourceCase_);
  }

  public static final int CONTENT_FIELD_NUMBER = 1;
  /**
   * <pre>
   * The audio data bytes encoded as specified in
   * `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
   * pure binary representation, whereas JSON representations use base64.
   * </pre>
   *
   * <code>optional bytes content = 1 [ctype = CORD];</code>
   */
  public com.google.protobuf.ByteString getContent() {
    if (audioSourceCase_ == 1) {
      return (com.google.protobuf.ByteString) audioSource_;
    }
    return com.google.protobuf.ByteString.EMPTY;
  }

  public static final int URI_FIELD_NUMBER = 2;
  /**
   * <pre>
   * URI that points to a file that contains audio data bytes as specified in
   * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
   * supported, which must be specified in the following format:
   * `gs://bucket_name/object_name` (other URI formats return
   * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
   * [Request URIs](/storage/docs/reference-uris).
   * </pre>
   *
   * <code>optional string uri = 2;</code>
   */
  public java.lang.String getUri() {
    java.lang.Object ref = "";
    if (audioSourceCase_ == 2) {
      ref = audioSource_;
    }
    if (ref instanceof java.lang.String) {
      return (java.lang.String) ref;
    } else {
      com.google.protobuf.ByteString bs = 
          (com.google.protobuf.ByteString) ref;
      java.lang.String s = bs.toStringUtf8();
      if (audioSourceCase_ == 2) {
        audioSource_ = s;
      }
      return s;
    }
  }
  /**
   * <pre>
   * URI that points to a file that contains audio data bytes as specified in
   * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
   * supported, which must be specified in the following format:
   * `gs://bucket_name/object_name` (other URI formats return
   * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
   * [Request URIs](/storage/docs/reference-uris).
   * </pre>
   *
   * <code>optional string uri = 2;</code>
   */
  public com.google.protobuf.ByteString
      getUriBytes() {
    java.lang.Object ref = "";
    if (audioSourceCase_ == 2) {
      ref = audioSource_;
    }
    if (ref instanceof java.lang.String) {
      com.google.protobuf.ByteString b = 
          com.google.protobuf.ByteString.copyFromUtf8(
              (java.lang.String) ref);
      if (audioSourceCase_ == 2) {
        audioSource_ = b;
      }
      return b;
    } else {
      return (com.google.protobuf.ByteString) ref;
    }
  }

  private byte memoizedIsInitialized = -1;
  public final boolean isInitialized() {
    byte isInitialized = memoizedIsInitialized;
    if (isInitialized == 1) return true;
    if (isInitialized == 0) return false;

    memoizedIsInitialized = 1;
    return true;
  }

  public void writeTo(com.google.protobuf.CodedOutputStream output)
                      throws java.io.IOException {
    if (audioSourceCase_ == 1) {
      output.writeBytes(
          1, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) audioSource_));
    }
    if (audioSourceCase_ == 2) {
      com.google.protobuf.GeneratedMessage.writeString(output, 2, audioSource_);
    }
  }

  public int getSerializedSize() {
    int size = memoizedSize;
    if (size != -1) return size;

    size = 0;
    if (audioSourceCase_ == 1) {
      size += com.google.protobuf.CodedOutputStream
        .computeBytesSize(
            1, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) audioSource_));
    }
    if (audioSourceCase_ == 2) {
      size += com.google.protobuf.GeneratedMessage.computeStringSize(2, audioSource_);
    }
    memoizedSize = size;
    return size;
  }

  private static final long serialVersionUID = 0L;
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      com.google.protobuf.ByteString data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      com.google.protobuf.ByteString data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(byte[] data)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      byte[] data,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws com.google.protobuf.InvalidProtocolBufferException {
    return PARSER.parseFrom(data, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseDelimitedFrom(java.io.InputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseDelimitedWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseDelimitedFrom(
      java.io.InputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      com.google.protobuf.CodedInputStream input)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input);
  }
  public static com.google.cloud.speech.v1beta1.RecognitionAudio parseFrom(
      com.google.protobuf.CodedInputStream input,
      com.google.protobuf.ExtensionRegistryLite extensionRegistry)
      throws java.io.IOException {
    return com.google.protobuf.GeneratedMessage
        .parseWithIOException(PARSER, input, extensionRegistry);
  }

  public Builder newBuilderForType() { return newBuilder(); }
  public static Builder newBuilder() {
    return DEFAULT_INSTANCE.toBuilder();
  }
  public static Builder newBuilder(com.google.cloud.speech.v1beta1.RecognitionAudio prototype) {
    return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
  }
  public Builder toBuilder() {
    return this == DEFAULT_INSTANCE
        ? new Builder() : new Builder().mergeFrom(this);
  }

  @java.lang.Override
  protected Builder newBuilderForType(
      com.google.protobuf.GeneratedMessage.BuilderParent parent) {
    Builder builder = new Builder(parent);
    return builder;
  }
  /**
   * <pre>
   * Contains audio data in the encoding specified in the `RecognitionConfig`.
   * Either `content` or `uri` must be supplied. Supplying both or neither
   * returns [google.rpc.Code.INVALID_ARGUMENT][].
   * </pre>
   *
   * Protobuf type {@code google.cloud.speech.v1beta1.RecognitionAudio}
   */
  public static final class Builder extends
      com.google.protobuf.GeneratedMessage.Builder<Builder> implements
      // @@protoc_insertion_point(builder_implements:google.cloud.speech.v1beta1.RecognitionAudio)
      com.google.cloud.speech.v1beta1.RecognitionAudioOrBuilder {
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return com.google.cloud.speech.v1beta1.SpeechProto.internal_static_google_cloud_speech_v1beta1_RecognitionAudio_descriptor;
    }

    protected com.google.protobuf.GeneratedMessage.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return com.google.cloud.speech.v1beta1.SpeechProto.internal_static_google_cloud_speech_v1beta1_RecognitionAudio_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              com.google.cloud.speech.v1beta1.RecognitionAudio.class, com.google.cloud.speech.v1beta1.RecognitionAudio.Builder.class);
    }

    // Construct using com.google.cloud.speech.v1beta1.RecognitionAudio.newBuilder()
    private Builder() {
      maybeForceBuilderInitialization();
    }

    private Builder(
        com.google.protobuf.GeneratedMessage.BuilderParent parent) {
      super(parent);
      maybeForceBuilderInitialization();
    }
    private void maybeForceBuilderInitialization() {
      if (com.google.protobuf.GeneratedMessage.alwaysUseFieldBuilders) {
      }
    }
    public Builder clear() {
      super.clear();
      audioSourceCase_ = 0;
      audioSource_ = null;
      return this;
    }

    public com.google.protobuf.Descriptors.Descriptor
        getDescriptorForType() {
      return com.google.cloud.speech.v1beta1.SpeechProto.internal_static_google_cloud_speech_v1beta1_RecognitionAudio_descriptor;
    }

    public com.google.cloud.speech.v1beta1.RecognitionAudio getDefaultInstanceForType() {
      return com.google.cloud.speech.v1beta1.RecognitionAudio.getDefaultInstance();
    }

    public com.google.cloud.speech.v1beta1.RecognitionAudio build() {
      com.google.cloud.speech.v1beta1.RecognitionAudio result = buildPartial();
      if (!result.isInitialized()) {
        throw newUninitializedMessageException(result);
      }
      return result;
    }

    public com.google.cloud.speech.v1beta1.RecognitionAudio buildPartial() {
      com.google.cloud.speech.v1beta1.RecognitionAudio result = new com.google.cloud.speech.v1beta1.RecognitionAudio(this);
      if (audioSourceCase_ == 1) {
        result.audioSource_ = audioSource_;
      }
      if (audioSourceCase_ == 2) {
        result.audioSource_ = audioSource_;
      }
      result.audioSourceCase_ = audioSourceCase_;
      onBuilt();
      return result;
    }

    public Builder mergeFrom(com.google.protobuf.Message other) {
      if (other instanceof com.google.cloud.speech.v1beta1.RecognitionAudio) {
        return mergeFrom((com.google.cloud.speech.v1beta1.RecognitionAudio)other);
      } else {
        super.mergeFrom(other);
        return this;
      }
    }

    public Builder mergeFrom(com.google.cloud.speech.v1beta1.RecognitionAudio other) {
      if (other == com.google.cloud.speech.v1beta1.RecognitionAudio.getDefaultInstance()) return this;
      switch (other.getAudioSourceCase()) {
        case CONTENT: {
          setContent(other.getContent());
          break;
        }
        case URI: {
          audioSourceCase_ = 2;
          audioSource_ = other.audioSource_;
          onChanged();
          break;
        }
        case AUDIOSOURCE_NOT_SET: {
          break;
        }
      }
      onChanged();
      return this;
    }

    public final boolean isInitialized() {
      return true;
    }

    public Builder mergeFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      com.google.cloud.speech.v1beta1.RecognitionAudio parsedMessage = null;
      try {
        parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        parsedMessage = (com.google.cloud.speech.v1beta1.RecognitionAudio) e.getUnfinishedMessage();
        throw e.unwrapIOException();
      } finally {
        if (parsedMessage != null) {
          mergeFrom(parsedMessage);
        }
      }
      return this;
    }
    private int audioSourceCase_ = 0;
    private java.lang.Object audioSource_;
    public AudioSourceCase
        getAudioSourceCase() {
      return AudioSourceCase.forNumber(
          audioSourceCase_);
    }

    public Builder clearAudioSource() {
      audioSourceCase_ = 0;
      audioSource_ = null;
      onChanged();
      return this;
    }


    /**
     * <pre>
     * The audio data bytes encoded as specified in
     * `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
     * pure binary representation, whereas JSON representations use base64.
     * </pre>
     *
     * <code>optional bytes content = 1 [ctype = CORD];</code>
     */
    public com.google.protobuf.ByteString getContent() {
      if (audioSourceCase_ == 1) {
        return (com.google.protobuf.ByteString) audioSource_;
      }
      return com.google.protobuf.ByteString.EMPTY;
    }
    /**
     * <pre>
     * The audio data bytes encoded as specified in
     * `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
     * pure binary representation, whereas JSON representations use base64.
     * </pre>
     *
     * <code>optional bytes content = 1 [ctype = CORD];</code>
     */
    public Builder setContent(com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  audioSourceCase_ = 1;
      audioSource_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * The audio data bytes encoded as specified in
     * `RecognitionConfig`. Note: as with all bytes fields, protobuffers use a
     * pure binary representation, whereas JSON representations use base64.
     * </pre>
     *
     * <code>optional bytes content = 1 [ctype = CORD];</code>
     */
    public Builder clearContent() {
      if (audioSourceCase_ == 1) {
        audioSourceCase_ = 0;
        audioSource_ = null;
        onChanged();
      }
      return this;
    }

    /**
     * <pre>
     * URI that points to a file that contains audio data bytes as specified in
     * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
     * supported, which must be specified in the following format:
     * `gs://bucket_name/object_name` (other URI formats return
     * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
     * [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string uri = 2;</code>
     */
    public java.lang.String getUri() {
      java.lang.Object ref = "";
      if (audioSourceCase_ == 2) {
        ref = audioSource_;
      }
      if (!(ref instanceof java.lang.String)) {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (audioSourceCase_ == 2) {
          audioSource_ = s;
        }
        return s;
      } else {
        return (java.lang.String) ref;
      }
    }
    /**
     * <pre>
     * URI that points to a file that contains audio data bytes as specified in
     * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
     * supported, which must be specified in the following format:
     * `gs://bucket_name/object_name` (other URI formats return
     * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
     * [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string uri = 2;</code>
     */
    public com.google.protobuf.ByteString
        getUriBytes() {
      java.lang.Object ref = "";
      if (audioSourceCase_ == 2) {
        ref = audioSource_;
      }
      if (ref instanceof String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        if (audioSourceCase_ == 2) {
          audioSource_ = b;
        }
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }
    /**
     * <pre>
     * URI that points to a file that contains audio data bytes as specified in
     * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
     * supported, which must be specified in the following format:
     * `gs://bucket_name/object_name` (other URI formats return
     * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
     * [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string uri = 2;</code>
     */
    public Builder setUri(
        java.lang.String value) {
      if (value == null) {
    throw new NullPointerException();
  }
  audioSourceCase_ = 2;
      audioSource_ = value;
      onChanged();
      return this;
    }
    /**
     * <pre>
     * URI that points to a file that contains audio data bytes as specified in
     * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
     * supported, which must be specified in the following format:
     * `gs://bucket_name/object_name` (other URI formats return
     * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
     * [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string uri = 2;</code>
     */
    public Builder clearUri() {
      if (audioSourceCase_ == 2) {
        audioSourceCase_ = 0;
        audioSource_ = null;
        onChanged();
      }
      return this;
    }
    /**
     * <pre>
     * URI that points to a file that contains audio data bytes as specified in
     * `RecognitionConfig`. Currently, only Google Cloud Storage URIs are
     * supported, which must be specified in the following format:
     * `gs://bucket_name/object_name` (other URI formats return
     * [google.rpc.Code.INVALID_ARGUMENT][]). For more information, see
     * [Request URIs](/storage/docs/reference-uris).
     * </pre>
     *
     * <code>optional string uri = 2;</code>
     */
    public Builder setUriBytes(
        com.google.protobuf.ByteString value) {
      if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
      audioSourceCase_ = 2;
      audioSource_ = value;
      onChanged();
      return this;
    }
    public final Builder setUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }

    public final Builder mergeUnknownFields(
        final com.google.protobuf.UnknownFieldSet unknownFields) {
      return this;
    }


    // @@protoc_insertion_point(builder_scope:google.cloud.speech.v1beta1.RecognitionAudio)
  }

  // @@protoc_insertion_point(class_scope:google.cloud.speech.v1beta1.RecognitionAudio)
  private static final com.google.cloud.speech.v1beta1.RecognitionAudio DEFAULT_INSTANCE;
  static {
    DEFAULT_INSTANCE = new com.google.cloud.speech.v1beta1.RecognitionAudio();
  }

  public static com.google.cloud.speech.v1beta1.RecognitionAudio getDefaultInstance() {
    return DEFAULT_INSTANCE;
  }

  private static final com.google.protobuf.Parser<RecognitionAudio>
      PARSER = new com.google.protobuf.AbstractParser<RecognitionAudio>() {
    public RecognitionAudio parsePartialFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
        return new RecognitionAudio(input, extensionRegistry);
    }
  };

  public static com.google.protobuf.Parser<RecognitionAudio> parser() {
    return PARSER;
  }

  @java.lang.Override
  public com.google.protobuf.Parser<RecognitionAudio> getParserForType() {
    return PARSER;
  }

  public com.google.cloud.speech.v1beta1.RecognitionAudio getDefaultInstanceForType() {
    return DEFAULT_INSTANCE;
  }

}

